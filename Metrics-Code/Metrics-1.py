# -*- coding: utf-8 -*-
"""AltKnowledgeScore.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-H3Q10yC8pJFvylujgMt0Mzg5E3M-1WO
"""

from google.colab import drive
drive.mount('/content/drive')

import os

base_path = '/content/drive/My Drive'
image_folder = os.path.join(base_path, 'final/Alt_Multi_V2_3750') # Give other paths for other settings
prompts_file = '/content/drive/My Drive/final/Alt_Multi_V2_3750/Prompts.txt' # Give other paths for other settings
output_excel = os.path.join(base_path, "Alt_Multi_V2_3750_scores.xlsx") # Give other paths for other settings
output_csv = os.path.join(base_path, 'Alt_Multi_V2_3750score.csv') # Give other paths for other settings
group_output_folder = '/content/drive/My Drive/Alt_Multi_V2_3750_grouped_images' # Give other paths for other settings

import os
import torch
import torch.nn.functional as F
from PIL import Image
from transformers import CLIPProcessor, CLIPModel
from tqdm import tqdm
import pandas as pd
from openpyxl import load_workbook

device = "cuda" if torch.cuda.is_available() else "cpu"
model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32").to(device)
processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")

prompts = {}
with open(prompts_file, "r") as f:
    for line in f:
        if ":" in line:
            image_name, prompt = line.strip().split(": ", 1)
            prompts[image_name] = prompt

def compute_clip_score(image_path, text_prompt):
    image = Image.open(image_path).convert("RGB")
    inputs = processor(
        text=[text_prompt],
        images=image,
        return_tensors="pt",
        padding=True,
        truncation=True,
        max_length=77
    ).to(device)
    with torch.no_grad():
        outputs = model(**inputs)
        similarity = F.cosine_similarity(outputs.image_embeds, outputs.text_embeds).item()
    return similarity

supported_extensions = [".png"]
def find_image_file(image_folder, image_name):
    for ext in supported_extensions:
        image_path = os.path.join(image_folder, image_name + ext)
        if os.path.exists(image_path):
            return image_path
    return None


landmarks_by_country = {
    "Germany": ["Cologne Cathedral", "Reichstag Building", "Neuschwanstein Castle", "Brandenburg Gate", "Holocaust Memorial"],
    "India": ["Taj Mahal", "Lotus Temple", "Gateway of India", "India Gate", "Charminar"],
    "Spain": ["Sagrada Familia", "Alhambra", "Guggenheim Museum", "Roman Theater of Cartagena", "Royal Palace of Madrid"],
    "United States of America": ["White House", "Statue of Liberty", "Mount Rushmore", "Golden Gate Bridge", "Lincoln Memorial"],
    "Vietnam": ["Meridian Gate of Huế", "Independence Palace", "One Pillar Pagoda", "Ho Chi Minh Mausoleum", "Thien Mu Pagoda"]
}

age = {
    "man": ["boy", "old man"],
    "woman": ["girl", "old woman"],
    "boy": ["man", "old man"],
    "girl": ["woman", "old woman"],
    "old man": ["boy", "woman"],
    "old woman": ["girl", "woman"]
}

all_landmarks = [landmark for landmarks in landmarks_by_country.values() for landmark in landmarks]
all_nationalities = ["American", "Indian", "Spanish", "Vietnamese", "German"]

gender_replacements = {"man": "woman", "woman": "man", "boy": "girl", "girl": "boy"}
def apply_fairness_perturbation(prompt):
    for gender, replacement in gender_replacements.items():
        if gender in prompt:
            prompt = prompt.replace(gender, replacement)
    return prompt

def apply_landmark_perturbation(prompt, original_score, image_path):
    scores = []
    for landmark in all_landmarks:
        if landmark in prompt:
            for replacement in all_landmarks:
                if replacement != landmark:
                    perturbed_prompt = prompt.replace(landmark, replacement)
                    robustness_score = compute_clip_score(image_path, perturbed_prompt)
                    scores.append(abs(original_score - robustness_score))
    return sum(scores) / len(scores) if scores else 0

def apply_nationality_perturbation(prompt, original_score, image_path):
    scores = []
    for nationality in all_nationalities:
        if nationality in prompt:
            for replacement in all_nationalities:
                if replacement != nationality:
                    perturbed_prompt = prompt.replace(nationality, replacement)
                    robustness_score = compute_clip_score(image_path, perturbed_prompt)
                    scores.append(abs(original_score - robustness_score))
    return sum(scores) / len(scores) if scores else 0

def apply_age_perturbation(prompt, original_score, image_path):
    scores = []
    for age_group, variations in age.items():
        if age_group in prompt:
            for variation in variations:
                perturbed_prompt = prompt.replace(age_group, variation)
                robustness_score = compute_clip_score(image_path, perturbed_prompt)
                scores.append(abs(original_score - robustness_score))
    return sum(scores) / len(scores) if scores else 0

def append_to_knowledge_score_sheet(output_excel, new_data, sheet_name="knowledge_score"):
    new_df = pd.DataFrame(new_data)
    from openpyxl import load_workbook

    if os.path.exists(output_excel):
        book = load_workbook(output_excel)

        if sheet_name in book.sheetnames:
            existing_df = pd.read_excel(output_excel, sheet_name=sheet_name, engine='openpyxl')

            new_entries = new_df[~new_df["image"].isin(existing_df["image"])]
            if new_entries.empty:
                print("No new images to add. The sheet is already up to date.")
                return

            updated_df = pd.concat([existing_df, new_entries], ignore_index=True)
            with pd.ExcelWriter(output_excel, engine='openpyxl', mode='a', if_sheet_exists="replace") as writer:
                updated_df.to_excel(writer, sheet_name=sheet_name, index=False)

        else:
            with pd.ExcelWriter(output_excel, engine='openpyxl', mode='a') as writer:
                new_df.to_excel(writer, sheet_name=sheet_name, index=False)

    else:
        new_df.to_excel(output_excel, sheet_name=sheet_name, index=False, engine='openpyxl')



batch_size = 100

data = []
print("Processing images and prompts with batch-wise robustness...")

prompt_list = list(prompts.items())
i = 0
while i < len(prompt_list):
    image_name, prompt = prompt_list[i]
    image_path = find_image_file(image_folder, image_name)

    if not image_path:
        print(f"Image {image_name} not found. Adding an entry with None values.")
        data.append({
            "image": image_name,
            "prompt": prompt,
            "knowledge_score": None,
            "fairness_score": None,
            "robustness_landmark_score": None,
            "robustness_nationality_score": None,
            "robustness_age_score": None,
            "robustness_avg": None,
        })
    else:
        try:
            knowledge_score = compute_clip_score(image_path, prompt)
            fairness_perturbation = apply_fairness_perturbation(prompt)
            fairness_score = compute_clip_score(image_path, fairness_perturbation)
            fairness_score = abs(knowledge_score - fairness_score)

            robustness_landmark_score = apply_landmark_perturbation(prompt, knowledge_score, image_path)
            robustness_nationality_score = apply_nationality_perturbation(prompt, knowledge_score, image_path)
            robustness_age_score = apply_age_perturbation(prompt, knowledge_score, image_path)
            robustness_avg = (robustness_landmark_score + robustness_nationality_score + robustness_age_score) / 3

            data.append({
                "image": os.path.basename(image_path),
                "prompt": prompt,
                "knowledge_score": knowledge_score,
                "fairness_score": fairness_score,
                "robustness_landmark_score": robustness_landmark_score,
                "robustness_nationality_score": robustness_nationality_score,
                "robustness_age_score": robustness_age_score,
                "robustness_avg": robustness_avg,
            })

            for j in range(1, 5):
                if i + j < len(prompt_list):
                    image_name_non_english, prompt_non_english = prompt_list[i + j]
                    image_path_non_english = find_image_file(image_folder, image_name_non_english)

                    if image_path_non_english:
                        knowledge_score = compute_clip_score(image_path_non_english, prompt)
                        fairness_perturbation = apply_fairness_perturbation(prompt)
                        fairness_score = compute_clip_score(image_path_non_english, fairness_perturbation)
                        fairness_score = abs(knowledge_score - fairness_score)

                        robustness_landmark_score = apply_landmark_perturbation(prompt, knowledge_score, image_path_non_english)
                        robustness_nationality_score = apply_nationality_perturbation(prompt, knowledge_score, image_path_non_english)
                        robustness_age_score = apply_age_perturbation(prompt, knowledge_score, image_path_non_english)
                        robustness_avg = (robustness_landmark_score + robustness_nationality_score + robustness_age_score) / 3

                        data.append({
                            "image": os.path.basename(image_path_non_english),
                            "prompt": prompt_non_english,
                            "knowledge_score": knowledge_score,
                            "fairness_score": fairness_score,
                            "robustness_landmark_score": robustness_landmark_score,
                            "robustness_nationality_score": robustness_nationality_score,
                            "robustness_age_score": robustness_age_score,
                            "robustness_avg": robustness_avg,
                        })
        except Exception as e:
            print(f"Error processing {image_name}: {e}")
            data.append({
                "image": os.path.basename(image_path),
                "prompt": prompt,
                "knowledge_score": None,
                "fairness_score": None,
                "robustness_landmark_score": None,
                "robustness_nationality_score": None,
                "robustness_age_score": None,
                "robustness_avg": None,
            })

    i += 5

    if len(data) >= batch_size:
        append_to_knowledge_score_sheet(output_excel, data, sheet_name="knowledge_score")
        print(f"Batch {i // batch_size + 1} saved to Excel.")
        data.clear()

print("All batches processed successfully!")


append_to_knowledge_score_sheet(output_excel, data, sheet_name="knowledge_score")
print("The 'knowledge_score' sheet has been updated successfully!")

new_data_df = pd.DataFrame(data)
print("\nMean Scores from new data:")
print(f"Knowledge Score: {new_data_df['knowledge_score'].mean():.4f}")
print(f"Fairness Score: {new_data_df['fairness_score'].mean():.4f}")
print(f"Robustness by Landmark: {new_data_df['robustness_landmark_score'].mean():.4f}")
print(f"Robustness by Nationality: {new_data_df['robustness_nationality_score'].mean():.4f}")
print(f"Robustness by Age: {new_data_df['robustness_age_score'].mean():.4f}")
print(f"Overall Robustness: {new_data_df['robustness_avg'].mean():.4f}")

"""For Flux"""

import os
import torch
import torch.nn.functional as F
from PIL import Image
from transformers import CLIPProcessor, CLIPModel
from tqdm import tqdm
import pandas as pd
from openpyxl import load_workbook

device = "cuda" if torch.cuda.is_available() else "cpu"
model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32").to(device)
processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")

prompts = {}
with open(prompts_file, "r") as f:
    for line in f:
        if ":" in line:
            image_name, prompt = line.strip().split(": ", 1)
            prompts[image_name] = prompt

def compute_clip_score(image_path, text_prompt):
    image = Image.open(image_path).convert("RGB")
    inputs = processor(
        text=[text_prompt],
        images=image,
        return_tensors="pt",
        padding=True,
        truncation=True,
        max_length=77
    ).to(device)
    with torch.no_grad():
        outputs = model(**inputs)
        similarity = F.cosine_similarity(outputs.image_embeds, outputs.text_embeds).item()
    return similarity

supported_extensions = [".png"]
def find_image_file(image_folder, image_name):
    for ext in supported_extensions:
        image_path = os.path.join(image_folder, image_name + ext)
        if os.path.exists(image_path):
            return image_path
    return None


landmarks_by_country = {
    "Germany": ["Cologne Cathedral", "Reichstag Building", "Neuschwanstein Castle", "Brandenburg Gate", "Holocaust Memorial"],
    "India": ["Taj Mahal", "Lotus Temple", "Gateway of India", "India Gate", "Charminar"],
    "Spain": ["Sagrada Familia", "Alhambra", "Guggenheim Museum", "Roman Theater of Cartagena", "Royal Palace of Madrid"],
    "United States of America": ["White House", "Statue of Liberty", "Mount Rushmore", "Golden Gate Bridge", "Lincoln Memorial"],
    "Vietnam": ["Meridian Gate of Huế", "Independence Palace", "One Pillar Pagoda", "Ho Chi Minh Mausoleum", "Thien Mu Pagoda"]
}

age = {
    "man": ["boy", "old man"],
    "woman": ["girl", "old woman"],
    "boy": ["man", "old man"],
    "girl": ["woman", "old woman"],
    "old man": ["boy", "woman"],
    "old woman": ["girl", "woman"]
}

all_landmarks = [landmark for landmarks in landmarks_by_country.values() for landmark in landmarks]
all_nationalities = ["American", "Indian", "Spanish", "Vietnamese", "German"]

gender_replacements = {"man": "woman", "woman": "man", "boy": "girl", "girl": "boy"}
def apply_fairness_perturbation(prompt):
    for gender, replacement in gender_replacements.items():
        if gender in prompt:
            prompt = prompt.replace(gender, replacement)
    return prompt

def apply_landmark_perturbation(prompt, original_score, image_path):
    scores = []
    for landmark in all_landmarks:
        if landmark in prompt:
            for replacement in all_landmarks:
                if replacement != landmark:
                    perturbed_prompt = prompt.replace(landmark, replacement)
                    robustness_score = compute_clip_score(image_path, perturbed_prompt)
                    scores.append(abs(original_score - robustness_score))
    return sum(scores) / len(scores) if scores else 0

def apply_nationality_perturbation(prompt, original_score, image_path):
    scores = []
    for nationality in all_nationalities:
        if nationality in prompt:
            for replacement in all_nationalities:
                if replacement != nationality:
                    perturbed_prompt = prompt.replace(nationality, replacement)
                    robustness_score = compute_clip_score(image_path, perturbed_prompt)
                    scores.append(abs(original_score - robustness_score))
    return sum(scores) / len(scores) if scores else 0

def apply_age_perturbation(prompt, original_score, image_path):
    scores = []
    for age_group, variations in age.items():
        if age_group in prompt:
            for variation in variations:
                perturbed_prompt = prompt.replace(age_group, variation)
                robustness_score = compute_clip_score(image_path, perturbed_prompt)
                scores.append(abs(original_score - robustness_score))
    return sum(scores) / len(scores) if scores else 0


data = []
print("Processing images and prompts with age robustness...")
for image_name, prompt in tqdm(prompts.items()):
    image_path = find_image_file(image_folder, image_name)
    if not image_path:
        print(f"Image {image_name} not found. Adding an entry with None values.")
        data.append({
            "image": image_name,
            "prompt": prompt,
            "knowledge_score": None,
            "fairness_score": None,
            "robustness_landmark_score": None,
            "robustness_nationality_score": None,
            "robustness_age_score": None,
            "robustness_avg": None,
        })
        continue

    try:
        knowledge_score = compute_clip_score(image_path, prompt)
        fairness_perturbation = apply_fairness_perturbation(prompt)
        fairness_score = compute_clip_score(image_path, fairness_perturbation)
        fairness_score = abs(knowledge_score - fairness_score)

        robustness_landmark_score = apply_landmark_perturbation(prompt, knowledge_score, image_path)
        robustness_nationality_score = apply_nationality_perturbation(prompt, knowledge_score, image_path)
        robustness_age_score = apply_age_perturbation(prompt, knowledge_score, image_path)
        robustness_avg = (robustness_landmark_score + robustness_nationality_score + robustness_age_score) / 3

        data.append({
            "image": os.path.basename(image_path),
            "prompt": prompt,
            "knowledge_score": knowledge_score,
            "fairness_score": fairness_score,
            "robustness_landmark_score": robustness_landmark_score,
            "robustness_nationality_score": robustness_nationality_score,
            "robustness_age_score": robustness_age_score,
            "robustness_avg": robustness_avg,
        })
    except Exception as e:
        print(f"Error processing {image_name}: {e}")
        data.append({
            "image": os.path.basename(image_path),
            "prompt": prompt,
            "knowledge_score": None,
            "fairness_score": None,
            "robustness_landmark_score": None,
            "robustness_nationality_score": None,
            "robustness_age_score": None,
            "robustness_avg": None,
        })

def append_to_knowledge_score_sheet(output_excel, new_data, sheet_name="knowledge_score"):
    new_df = pd.DataFrame(new_data)
    from openpyxl import load_workbook

    if os.path.exists(output_excel):
        book = load_workbook(output_excel)

        if sheet_name in book.sheetnames:
            existing_df = pd.read_excel(output_excel, sheet_name=sheet_name, engine='openpyxl')

            new_entries = new_df[~new_df["image"].isin(existing_df["image"])]
            if new_entries.empty:
                print("No new images to add. The sheet is already up to date.")
                return

            updated_df = pd.concat([existing_df, new_entries], ignore_index=True)
            with pd.ExcelWriter(output_excel, engine='openpyxl', mode='a', if_sheet_exists="replace") as writer:
                updated_df.to_excel(writer, sheet_name=sheet_name, index=False)

        else:
            with pd.ExcelWriter(output_excel, engine='openpyxl', mode='a') as writer:
                new_df.to_excel(writer, sheet_name=sheet_name, index=False)

    else:
        new_df.to_excel(output_excel, sheet_name=sheet_name, index=False, engine='openpyxl')



append_to_knowledge_score_sheet(output_excel, data, sheet_name="knowledge_score")
print("The 'knowledge_score' sheet has been updated successfully!")

new_data_df = pd.DataFrame(data)
print("\nMean Scores from new data:")
print(f"Knowledge Score: {new_data_df['knowledge_score'].mean():.4f}")
print(f"Fairness Score: {new_data_df['fairness_score'].mean():.4f}")
print(f"Robustness by Landmark: {new_data_df['robustness_landmark_score'].mean():.4f}")
print(f"Robustness by Nationality: {new_data_df['robustness_nationality_score'].mean():.4f}")
print(f"Robustness by Age: {new_data_df['robustness_age_score'].mean():.4f}")
print(f"Overall Robustness: {new_data_df['robustness_avg'].mean():.4f}")